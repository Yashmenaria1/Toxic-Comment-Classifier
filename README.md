# Toxic-Comment-Classifier
This is a Toxic Comment Classifier model, which classifies text according to whether it exhibits offensive attributes (i.e. Insult, Obscene, Severe Toxicity).

Classifying all Comments.


![image](https://github.com/Yashmenaria1/Toxic-Comment-Classifier/assets/107399779/f1d8a6ac-6001-420e-a444-b1b6c26b996f)

After Classifying.

Result:

![image](https://github.com/Yashmenaria1/Toxic-Comment-Classifier/assets/107399779/caae911f-dcab-42cd-a7c3-341e25caf251)
